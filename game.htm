<!DOCTYPE html>
<html>
<title>projects</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1" />
<style>

body {
	font: normal 100% Courier New, sans-serif;
	margin:0;
}

.content hr {
	margin-left: auto;
	margin-right: auto;
	margin-bottom: 2em;
	width: 70%;
}

.content ul {
	display: block;
	margin-left: auto;
	margin-right: auto;
	width: 70%;
	font-size: 1em;
	line-height: 1.8;
	margin-top: -1em;
	margin-bottom: 3em;
}

.content h1 {
	margin-top: 3em;
	margin-left: auto;
	margin-right: auto;
	width: 70%;
	margin-bottom: 1em;
}

.content h2 {
	margin-top: 1.5em;
	margin-left: auto;
	margin-right: auto;
	width: 70%;
}

.content p {
	display: block;
	margin-left: auto;
	margin-right: auto;
	width: 70%;
	font-size: 1em;
	/*text-align: justify;*/
	line-height: 1.8;
	margin-top: -1em;
	margin-bottom: 3em;
}


</style>

<body>
	<div class='content'>
		<h1>PROJECT DESCRIPTION</h1>
		<p>Webscraping, APIs, and Natural Language Processing (NLP).</p>
		<ul>
  			<li>Applied CountVectorizer to tokenize all content.</li>
  			<li>TApplied models include Logistic Regression, RandomForest, and Gradient Boosting Regression Tree.</li>
  			<li>Applied Confusion matrix for evaluating the performance of all models.</li>
		</ul>

		<h2>PROBLEM STATEMENT</h2>
		<hr />
		<p>Scraped game posts from Reddit and developed a Natural Language Processing model that identifies which content of posts belongs to board games and which content of posts belongs to card games. In addition, it would be better if was able to find more insight into all content.</p>

		<h2>DATA</h2>
		<hr />
		<p>Used Web APIs scrape game posts as datasets.</p>
		<ul>
  			<li>Scraped from Reddit.</li>
  			<li>Corpus: 4000 documents.</li>
  			<li>Feature amount: 5.</li>
  			<li>Type: String.</li>
		</ul>

		<h2>METHODOLOGY</h2>
		<hr />
		<p>Data Cleaning.</p>
		<ul>
  			<li>Getting rid of unnecessary features.</li>
  			<li>Data combination.</li>
		</ul>

		<h2>EXPLORATORY DATA ANALYSIS</h2>
		<hr />
		<ul>
  			<li>Found and visualized the distribution of length of authors' names.</li>
  			<li>Found the median number of words of title.</li>
  			<li>Found and visualized the distribution of number of words of title.</li>
  			<li>Found the average of letters of author's names between the calsses of board games and card games.</li>
  			<li>Found and visualized the most / least 20 most common words in dataset.</li>
		</ul>

		<h2>MODELING</h2>
		<hr />
		<ul>
  			<li>Used features as title and subreddit.</li>
  			<li>Used Logistic Regression, RandomForest, Gradient Boosting Regression Tree.</li>
  			<li>Used GridSearch and hyperparameter tuning.</li>
		</ul>

		<h2>RESULTS</h2>
		<hr />
		<ul>
  			<li>Logistic Regression, Train score: 0.622, Test score: 0.636, Confusion matrix, accuracy: 0.636.</li>
  			<li>RandomForest, Train score: 0.866, Test score: 0.834, Confusion matrix, accuracy: 0.834.</li>
  			<li>Gradient Boosting Regression Tree, Train score: 0.866, Test score: 0.834, Confusion matrix, accuracy: 0.834.</li>
		</ul>

		<h2>CONCLUSION</h2>
		<hr />
		<ul>
  			<li>In Logistic Regression model, evaluation metric tell its sensitivity is 0.625, specificity is 0.648.</li>
  			<li>In RondomForest model, evaluation metric tell its sensitivity is 0.786, specificity is 0.901.</li>
  			<li>In Gradient Boosting Regression Tree, evaluation metric tell its sensitivity is 0.786, specificity is 0.901.</li>
		</ul>

		<h2>NEXT STEP</h2>
		<hr />
		<p>To change CountVectorizer to TfidfVectorizer to try and want to see how that outcomes are different.</p>

</body>
</html>